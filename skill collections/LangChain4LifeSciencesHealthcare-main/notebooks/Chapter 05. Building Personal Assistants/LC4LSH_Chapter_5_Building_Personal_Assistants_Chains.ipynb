{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1LHTs4mmDKG9DKfzNAM3xxxw9tL4kjfDU",
     "timestamp": 1714479824659
    }
   ],
   "authorship_tag": "ABX9TyOJcqhHZRTrNK6Rl0Vb9Xz+"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Code to Chapter 5 of LangChain for Life Science and Healthcare book, by Dr. Ivan Reznikov\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1wln-l-rvC_CM_OZ11psJIU_bJba6ETeh?usp=sharing)"
   ],
   "metadata": {
    "id": "-2zXtaCNw_Gj"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook demonstrates how to build personal assistants using LangChain's chain capabilities. We'll explore various chain types including history-aware retrievers, sequential chains, and parallel chains for different use cases in life sciences and research.\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Chain Composition**: Use LCEL for clean, readable chain building\n",
    "- **Context Awareness**: History-aware retrievers improve conversational AI\n",
    "- **Parallel Processing**: Optimize performance with simultaneous operations\n",
    "- **Modularity**: Break complex tasks into smaller, manageable chains\n",
    "- **Testing**: Always test chains with various inputs to ensure robustness\n",
    "- **Visualization**: Use `get_graph().print_ascii()` to understand chain structure"
   ],
   "metadata": {
    "id": "qEX4FpevxKGS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Package Installation"
   ],
   "metadata": {
    "id": "e7_xrH8KxOrz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UAeZMnUQMMyR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545609837,
     "user_tz": -240,
     "elapsed": 50507,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "outputId": "f4eb3cbe-dbb4-41e9-e263-2cf52441ab11"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/91.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.8/367.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.1 which is incompatible.\n",
      "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\n",
      "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -U langchain  \\\n",
    "  langchainhub \\\n",
    "  langchain-community \\\n",
    "  langchain-core \\\n",
    "  langchain-experimental \\\n",
    "  langchain-openai \\\n",
    "  langchain-text-splitters \\\n",
    "  langcodes \\\n",
    "  langgraph \\\n",
    "  langsmith \\\n",
    "  libclang \\\n",
    "  openai pandas matplotlib docarray grandalf semanticscholar arxiv xmltodict faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip freeze | grep \"lang\\|openai\\|chroma\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XO2w47CNMmPh",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545611671,
     "user_tz": -240,
     "elapsed": 1814,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "outputId": "54b7e91d-5301-488f-8b31-5375f5f73ae0"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "google-ai-generativelanguage==0.6.15\n",
      "google-cloud-language==2.17.2\n",
      "langchain==0.3.26\n",
      "langchain-community==0.3.27\n",
      "langchain-core==0.3.68\n",
      "langchain-experimental==0.3.4\n",
      "langchain-openai==0.3.28\n",
      "langchain-text-splitters==0.3.8\n",
      "langchainhub==0.1.21\n",
      "langcodes==3.5.0\n",
      "langgraph==0.5.3\n",
      "langgraph-checkpoint==2.1.0\n",
      "langgraph-prebuilt==0.5.2\n",
      "langgraph-sdk==0.1.73\n",
      "langsmith==0.4.5\n",
      "language_data==1.3.0\n",
      "libclang==18.1.1\n",
      "openai==1.95.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "\n",
    "# Set OpenAI API key from Google Colab's user environment or default\n",
    "def set_api_keys(\n",
    "    default_openai_key: str = \"YOUR_API_KEY\", default_tavily_key: str = \"YOUR_API_KEY\"\n",
    ") -> None:\n",
    "    \"\"\"Set the OpenAI API key from Google Colab's user environment or use a default value.\"\"\"\n",
    "\n",
    "    os.environ[\"OPENAI_API_KEY\"] = (\n",
    "        userdata.get(\"LC4LS_OPENAI_API_KEY\") or default_openai_key\n",
    "    )\n",
    "\n",
    "\n",
    "set_api_keys()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"lc4ls-ch5-lcel-chains\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")"
   ],
   "metadata": {
    "id": "BN2iXeNnMqqO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545612891,
     "user_tz": -240,
     "elapsed": 1198,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## History-Aware Retrieval Chain\n",
    "\n",
    "### What is a History-Aware Retrieval Chain?\n",
    "A history-aware retrieval chain is a sophisticated RAG (Retrieval-Augmented Generation) system that considers conversation history when retrieving relevant documents. This allows the system to understand context from previous messages and provide more accurate responses.\n"
   ],
   "metadata": {
    "id": "2ZXwCxV-xpve"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain import hub\n",
    "from langchain_core.prompts import MessagesPlaceholder, ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# Initialize LLM and embedding model\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Sample documents (replace with your actual data)\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Experiment A: We tested the effect of fertilizer X on tomato yield at temperature 80°F. Results showed a 20% increase in yield in the experimental group.\"\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Experiment B: We tested the effect of fertilizer X on corn yield. The experiment is ongoing.\"\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Experiment C: We tested the effect of compost and different temperatures on strawberry growth. Best results achieved at 25°C-30°C range.\"\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Experiment D: Examined the small influence of compost amount on soil acidity.\"\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Experiment E: Examined the influence of light intensity on photosynthesis in algae.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Create vector store\n",
    "vector = FAISS.from_documents(documents, embedding_model)\n",
    "retriever = vector.as_retriever(k=3)\n",
    "\n",
    "# Prompt for history-aware retrieval\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You help users find information about agricultural experiments.\n",
    "                Paraphrase the user's query based on the conversation history.\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create history-aware retriever chain\n",
    "history_aware_retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
   ],
   "metadata": {
    "id": "ShBk9vVPCjtz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545619517,
     "user_tz": -240,
     "elapsed": 6613,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test 1: Query with Context Updates"
   ],
   "metadata": {
    "id": "zzrt_64iydtW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "chat_history = [\n",
    "    HumanMessage(content=\"Experiment E actually used Fertilizer X.\"),\n",
    "    AIMessage(\n",
    "        content=\"Thank you for the correction. I'll note that Experiment E used Fertilizer X.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Experiment B had contamination issues and should be excluded from analysis.\"\n",
    "    ),\n",
    "    AIMessage(\n",
    "        content=\"Noted. I'll exclude Experiment B from all analysis due to contamination issues.\"\n",
    "    ),\n",
    "]"
   ],
   "metadata": {
    "id": "-Y_00qUxyTkB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545619519,
     "user_tz": -240,
     "elapsed": 22,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "query = \"List all experiment where fertilizer X was used\"\n",
    "\n",
    "# Invoke the retriever chain\n",
    "result = history_aware_retriever_chain.invoke(\n",
    "    {\"chat_history\": chat_history, \"input\": query}\n",
    ")"
   ],
   "metadata": {
    "id": "gGUVUaJ0M_7R",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545620659,
     "user_tz": -240,
     "elapsed": 1159,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "**Expected Result**: The system should retrieve documents related to fertilizer X, considering the conversation history that Experiment E used Fertilizer X and Experiment B should be excluded.\n"
   ],
   "metadata": {
    "id": "gmrhRKFVyJmh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "result"
   ],
   "metadata": {
    "id": "gbgw_1k0PyOf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545620688,
     "user_tz": -240,
     "elapsed": 28,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "756e0318-3590-47aa-aa0a-fd307f5235cc"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Document(id='f5c83a87-3a2a-4505-b59b-02a726a4b268', metadata={}, page_content='Experiment B: We tested the effect of fertilizer X on corn yield. The experiment is ongoing.'),\n",
       " Document(id='7ccc664d-bb0a-4245-8439-3a809ea5a906', metadata={}, page_content='Experiment A: We tested the effect of fertilizer X on tomato yield at temperature 80°F. Results showed a 20% increase in yield in the experimental group.'),\n",
       " Document(id='63618ca3-de82-4633-aa37-ee5111bd5388', metadata={}, page_content='Experiment D: Examined the small influence of compost amount on soil acidity.'),\n",
       " Document(id='031c5d80-ac69-4e33-8825-9794f590131a', metadata={}, page_content='Experiment E: Examined the influence of light intensity on photosynthesis in algae.')]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "system_prompt = \"\"\"You are an assistant for question-answering tasks.\n",
    "    Use the following pieces of retrieved context to answer\n",
    "    the question. If you don't know the answer, say that you\n",
    "    don't know. Always use the metric system to answer questions!\n",
    "    {context}\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever_chain, question_answer_chain)"
   ],
   "metadata": {
    "id": "BTE_TCLDPPXd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545620735,
     "user_tz": -240,
     "elapsed": 45,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result = rag_chain.invoke({\"input\": query, \"chat_history\": chat_history})"
   ],
   "metadata": {
    "id": "JDhJmWt7Po9T",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545623059,
     "user_tz": -240,
     "elapsed": 2321,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dqo_dan4NAt3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545623084,
     "user_tz": -240,
     "elapsed": 23,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "outputId": "01b705d8-9289-4178-8656-a7b129a1f6df"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input': 'List all experiment where fertilizer X was used',\n",
       " 'chat_history': [HumanMessage(content='Experiment E actually used Fertilizer X.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Thank you for the correction. I'll note that Experiment E used Fertilizer X.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Experiment B had contamination issues and should be excluded from analysis.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Noted. I'll exclude Experiment B from all analysis due to contamination issues.\", additional_kwargs={}, response_metadata={})],\n",
       " 'context': [Document(id='f5c83a87-3a2a-4505-b59b-02a726a4b268', metadata={}, page_content='Experiment B: We tested the effect of fertilizer X on corn yield. The experiment is ongoing.'),\n",
       "  Document(id='7ccc664d-bb0a-4245-8439-3a809ea5a906', metadata={}, page_content='Experiment A: We tested the effect of fertilizer X on tomato yield at temperature 80°F. Results showed a 20% increase in yield in the experimental group.'),\n",
       "  Document(id='63618ca3-de82-4633-aa37-ee5111bd5388', metadata={}, page_content='Experiment D: Examined the small influence of compost amount on soil acidity.'),\n",
       "  Document(id='031c5d80-ac69-4e33-8825-9794f590131a', metadata={}, page_content='Experiment E: Examined the influence of light intensity on photosynthesis in algae.')],\n",
       " 'answer': 'Fertilizer X was used in the following experiments:\\n\\n1. Experiment A: Tested the effect of fertilizer X on tomato yield.\\n2. Experiment B: Tested the effect of fertilizer X on corn yield.'}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test 2: Query Without Initial Context"
   ],
   "metadata": {
    "id": "2QEl_enfya3O"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "query = \"List all experiment where Fertilizer Y was used\"\n",
    "\n",
    "# Invoke the retriever chain\n",
    "result = history_aware_retriever_chain.invoke({\"chat_history\": [], \"input\": query})"
   ],
   "metadata": {
    "id": "-8gUNSW7U-3F",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545623375,
     "user_tz": -240,
     "elapsed": 272,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Expected Result**: The system should not find any experiments with Fertilizer Y since none are mentioned in the documents."
   ],
   "metadata": {
    "id": "VhGn_PFEylTc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "result"
   ],
   "metadata": {
    "id": "5Ht82O8DWk9b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545623406,
     "user_tz": -240,
     "elapsed": 20,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8121d4cb-bd3b-4102-e72e-b8b2ccdc7f03"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Document(id='f5c83a87-3a2a-4505-b59b-02a726a4b268', metadata={}, page_content='Experiment B: We tested the effect of fertilizer X on corn yield. The experiment is ongoing.'),\n",
       " Document(id='7ccc664d-bb0a-4245-8439-3a809ea5a906', metadata={}, page_content='Experiment A: We tested the effect of fertilizer X on tomato yield at temperature 80°F. Results showed a 20% increase in yield in the experimental group.'),\n",
       " Document(id='63618ca3-de82-4633-aa37-ee5111bd5388', metadata={}, page_content='Experiment D: Examined the small influence of compost amount on soil acidity.'),\n",
       " Document(id='031c5d80-ac69-4e33-8825-9794f590131a', metadata={}, page_content='Experiment E: Examined the influence of light intensity on photosynthesis in algae.')]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test 3: Query with Semantic Understanding"
   ],
   "metadata": {
    "id": "vl2UFwgZyjKc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "chat_history = [\n",
    "    HumanMessage(content=\"Was Fertilizer Y used in the experiemnts.?\"),\n",
    "    AIMessage(content=\"No, Fertilizer Y wasn't used in any of the experiments.\"),\n",
    "    HumanMessage(content=\"That's incorrect. Fertilizer Y and compost are the same.\"),\n",
    "    AIMessage(\n",
    "        content=\"Thank you for the correction. I'll note that Fertilizer Y and compost are the same.\"\n",
    "    ),\n",
    "]"
   ],
   "metadata": {
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545623423,
     "user_tz": -240,
     "elapsed": 3,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "id": "k0mFMuGrUg4z"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "query = \"List all experiment where Fertilizer Y was used\"\n",
    "\n",
    "# Create history-aware retriever chain\n",
    "history_aware_retriever_chain = create_history_aware_retriever(llm, retriever, prompt)\n",
    "\n",
    "# Invoke the retriever chain\n",
    "result = history_aware_retriever_chain.invoke(\n",
    "    {\"chat_history\": chat_history, \"input\": query}\n",
    ")"
   ],
   "metadata": {
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545624946,
     "user_tz": -240,
     "elapsed": 1502,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "id": "TpjyNmb2Ug40"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result"
   ],
   "metadata": {
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545624990,
     "user_tz": -240,
     "elapsed": 42,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "id": "e6JSITxXUg40",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "dff053cc-060f-4825-d34b-6e8f27190ad2"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Document(id='f5c83a87-3a2a-4505-b59b-02a726a4b268', metadata={}, page_content='Experiment B: We tested the effect of fertilizer X on corn yield. The experiment is ongoing.'),\n",
       " Document(id='7ccc664d-bb0a-4245-8439-3a809ea5a906', metadata={}, page_content='Experiment A: We tested the effect of fertilizer X on tomato yield at temperature 80°F. Results showed a 20% increase in yield in the experimental group.'),\n",
       " Document(id='63618ca3-de82-4633-aa37-ee5111bd5388', metadata={}, page_content='Experiment D: Examined the small influence of compost amount on soil acidity.'),\n",
       " Document(id='c7f675d1-596e-4284-98ac-2119abbf67a5', metadata={}, page_content='Experiment C: We tested the effect of compost and different temperatures on strawberry growth. Best results achieved at 25°C-30°C range.')]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "system_prompt = \"\"\"You are an assistant for question-answering tasks.\n",
    "    Use the following pieces of retrieved context to answer\n",
    "    the question. If you don't know the answer, say that you\n",
    "    don't know. Always use the metric system to answer questions!\n",
    "    {context}\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever_chain, question_answer_chain)"
   ],
   "metadata": {
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545624995,
     "user_tz": -240,
     "elapsed": 2,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "id": "b2dndvFyUg41"
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result = rag_chain.invoke({\"input\": query, \"chat_history\": chat_history})"
   ],
   "metadata": {
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545626676,
     "user_tz": -240,
     "elapsed": 1679,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "id": "BC7ofMQXUg41"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "**Expected Result**: The system should now understand that Fertilizer Y = compost and retrieve experiments C and D that used compost.\n"
   ],
   "metadata": {
    "id": "uzZoYYqGy3Li"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "result"
   ],
   "metadata": {
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545626703,
     "user_tz": -240,
     "elapsed": 25,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "id": "onsUZaarUg41",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "579c88fa-6aa1-4133-c59f-6717598f356a"
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input': 'List all experiment where Fertilizer Y was used',\n",
       " 'chat_history': [HumanMessage(content='Was Fertilizer Y used in the experiemnts.?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"No, Fertilizer Y wasn't used in any of the experiments.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"That's incorrect. Fertilizer Y and compost are the same.\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Thank you for the correction. I'll note that Fertilizer Y and compost are the same.\", additional_kwargs={}, response_metadata={})],\n",
       " 'context': [Document(id='f5c83a87-3a2a-4505-b59b-02a726a4b268', metadata={}, page_content='Experiment B: We tested the effect of fertilizer X on corn yield. The experiment is ongoing.'),\n",
       "  Document(id='7ccc664d-bb0a-4245-8439-3a809ea5a906', metadata={}, page_content='Experiment A: We tested the effect of fertilizer X on tomato yield at temperature 80°F. Results showed a 20% increase in yield in the experimental group.'),\n",
       "  Document(id='63618ca3-de82-4633-aa37-ee5111bd5388', metadata={}, page_content='Experiment D: Examined the small influence of compost amount on soil acidity.'),\n",
       "  Document(id='c7f675d1-596e-4284-98ac-2119abbf67a5', metadata={}, page_content='Experiment C: We tested the effect of compost and different temperatures on strawberry growth. Best results achieved at 25°C-30°C range.')],\n",
       " 'answer': \"I don't know.\"}"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic Chain Building with LCEL\n",
    "\n",
    "### What is LCEL?\n",
    "LangChain Expression Language (LCEL) is a declarative way to compose chains. It provides a simple syntax for building complex workflows using the pipe operator (|).\n"
   ],
   "metadata": {
    "id": "GZnkMkVqy4QH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ],
   "metadata": {
    "id": "VDP05i8vSP4A",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545626708,
     "user_tz": -240,
     "elapsed": 3,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"You are a chemist. Answer the following question: {question}\"\n",
    ")\n",
    "output_parser = StrOutputParser()"
   ],
   "metadata": {
    "id": "yJaaJbHqSI7h",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545626710,
     "user_tz": -240,
     "elapsed": 3,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chain 1: Direct Model Invocation"
   ],
   "metadata": {
    "id": "0eTIeguOzCYu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "chain_1 = model\n",
    "chain_1.invoke((\"human\", \"What is a bond?\"))"
   ],
   "metadata": {
    "id": "7UfMQxd85K9H",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545627946,
     "user_tz": -240,
     "elapsed": 1235,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b05c4433-59f1-4b59-b4f9-d0b781a5d392"
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AIMessage(content=\"A bond is a fixed income security that represents a loan made by an investor to a borrower, typically a corporation or government entity. When an investor purchases a bond, they are essentially lending money to the issuer in exchange for periodic interest payments and the return of the bond's face value at maturity. Bonds are typically used by companies and governments to raise funds for various projects and expenses.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 17, 'total_tokens': 93, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BtPSsJz8MgcmEkCf0e49TeHV7mGgu', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b95402a1-f546-48af-9ef0-6455096e46c1-0', usage_metadata={'input_tokens': 17, 'output_tokens': 76, 'total_tokens': 93, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chain 2: Prompt + Model"
   ],
   "metadata": {
    "id": "pYqioHohzHUx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "chain_2 = prompt | model\n",
    "chain_2.invoke({\"question\": \"What is a bond?\"})"
   ],
   "metadata": {
    "id": "WY0puf0wzDaU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545629007,
     "user_tz": -240,
     "elapsed": 1063,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "04f1f47a-bd06-466c-9d5a-91f3e5d98341"
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AIMessage(content='In chemistry, a bond is a force that holds two or more atoms together to form a molecule. Bonds are formed when atoms share or transfer electrons in order to achieve a more stable electron configuration. There are different types of chemical bonds, including covalent bonds, ionic bonds, and metallic bonds. Bonds are essential for the formation of compounds and play a crucial role in determining the properties of substances.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 23, 'total_tokens': 104, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BtPSuQkpdNTR17vdJ6pIy83ejk5Fy', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--1c2423ba-fa49-4096-85b6-67a183314dd0-0', usage_metadata={'input_tokens': 23, 'output_tokens': 81, 'total_tokens': 104, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chain 3: Complete Chain with Output Parser"
   ],
   "metadata": {
    "id": "cpkv4mYXzKB_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "chain_3 = prompt | model | output_parser\n",
    "chain_3.invoke({\"question\": \"What is a bond?\"})"
   ],
   "metadata": {
    "id": "crE_gxTIzDeU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545630240,
     "user_tz": -240,
     "elapsed": 1232,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "outputId": "260015a7-87b0-4d3e-8d99-d9529d05b88d"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'A bond in chemistry refers to the attractive force that holds atoms together in a molecule. This force can be due to the sharing of electrons between atoms (covalent bond), the transfer of electrons from one atom to another (ionic bond), or the attraction between positively and negatively charged ions (ionic bond). Bonds are essential for forming the structure of molecules and determining their physical and chemical properties.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 23
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "**Key Difference**: Chain 3 returns a clean string instead of a message object, making it easier to work with programmatically.\n"
   ],
   "metadata": {
    "id": "jyOGqu4szNma"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RAG Chain with Parallel Processing\n",
    "\n",
    "### What is Parallel Processing in Chains?\n",
    "Parallel processing allows multiple operations to run simultaneously, improving efficiency. In RAG systems, we can retrieve context and pass through the question in parallel.\n"
   ],
   "metadata": {
    "id": "jh-LDPoqzPz1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup Biology Knowledge Base"
   ],
   "metadata": {
    "id": "NSntmDysza5J"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\n",
    "        \"DNA carries genetic information within cell chromosomes.\",\n",
    "        \"Ecosystems consist of living organisms and their physical environment.\",\n",
    "        \"The human heart pumps blood through arteries and veins.\",\n",
    "        \"Some bacteria cause diseases while others are beneficial.\",\n",
    "        \"Homeostasis maintains steady internal conditions in living systems.\",\n",
    "        \"Natural selection helps organisms adapt and survive in their environments.\",\n",
    "        \"Mitochondria produce ATP, the main energy source for cells.\",\n",
    "        \"Photosynthesis in plants produces oxygen.\",\n",
    "        \"The brain controls body functions and is located in the skull.\",\n",
    "        \"The immune system defends against harmful substances by detecting antigens.\",\n",
    "    ],\n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-large\"),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ],
   "metadata": {
    "id": "mFXmn9dEzDhe",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545640633,
     "user_tz": -240,
     "elapsed": 10391,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5c1b834d-6a4b-4bdb-8ee4-fe50c43bb85d"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create RAG Chain with Parallel Processing"
   ],
   "metadata": {
    "id": "hOi2V8uwzf2R"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Setup retrieval and handling of inputs\n",
    "retrieval = RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "\n",
    "# Combine the components into a processing chain\n",
    "chain = retrieval | prompt | model | output_parser"
   ],
   "metadata": {
    "id": "IbnnU5GJzi0F",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545640635,
     "user_tz": -240,
     "elapsed": 6,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    }
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Biology RAG Chain"
   ],
   "metadata": {
    "id": "TVLhuCtDzohP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "result1 = chain.invoke(\"How do plants release oxygen?\")\n",
    "print(result1)"
   ],
   "metadata": {
    "id": "M3TlV35WAhK3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545641396,
     "user_tz": -240,
     "elapsed": 760,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "74337106-3472-4d0f-e9ab-41d43261f08c"
   },
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Plants release oxygen through photosynthesis.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "result2 = chain.invoke(\"What is the main energy source for cells?\")\n",
    "print(result2)"
   ],
   "metadata": {
    "id": "yKXW8GX9DdQb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545642184,
     "user_tz": -240,
     "elapsed": 786,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "48a67177-4080-42a5-96ca-fcbed011070e"
   },
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The main energy source for cells is ATP, which is produced by mitochondria.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "result3 = chain.invoke(\"Who painted mona Lisa?\")\n",
    "print(result3)"
   ],
   "metadata": {
    "id": "FYn699vRDdVF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545642748,
     "user_tz": -240,
     "elapsed": 536,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "37d5ac95-2351-4b8a-cecf-dc9473a86b94"
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The information provided does not mention anything about who painted the Mona Lisa.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Expected Results**:\n",
    "- Test 1: Should reference photosynthesis\n",
    "- Test 2: Should reference ATP and mitochondria\n",
    "- Test 3: Should indicate the answer is not in the context"
   ],
   "metadata": {
    "id": "-fnuv2cPzsCt"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sequential Chains for Medical Diagnosis\n",
    "\n",
    "### What are Sequential Chains?\n",
    "Sequential chains process information in steps, where the output of one chain becomes the input for the next. This is useful for multi-step reasoning tasks.\n"
   ],
   "metadata": {
    "id": "h_nbOJQRzxMQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Medical Diagnosis Chain"
   ],
   "metadata": {
    "id": "Z49pOuNNz3cW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Prompt to determine the disease based on symptoms\n",
    "prompt_symptom = ChatPromptTemplate.from_template(\n",
    "    \"Based on these symptoms, what disease might this person have: {symptoms}?\"\n",
    ")\n",
    "\n",
    "# Prompt to recommend lab exams based on the suspected disease\n",
    "prompt_disease = ChatPromptTemplate.from_template(\n",
    "    \"What lab exams should be taken to confirm a diagnosis of {disease}?\"\n",
    ")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# Chains to determine the disease from symptoms\n",
    "sub_chain_symptom = prompt_symptom | model | StrOutputParser()\n",
    "sub_chain_disease = prompt_disease | model | StrOutputParser()\n",
    "\n",
    "# Sequential chain: symptoms -> disease -> lab tests\n",
    "main_chain = {\"disease\": sub_chain_symptom} | sub_chain_disease"
   ],
   "metadata": {
    "id": "On2jaURa4l5z",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545642791,
     "user_tz": -240,
     "elapsed": 38,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    }
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize Chain Structure"
   ],
   "metadata": {
    "id": "TjJbu8wS0H1J"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "main_chain.get_graph().print_ascii()"
   ],
   "metadata": {
    "id": "bQbTFVSeaeYv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545642836,
     "user_tz": -240,
     "elapsed": 41,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "375a9888-55e7-42d6-99b3-2e98eb42b8b1"
   },
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------------+ \n",
      "| Parallel<disease>Input | \n",
      "+------------------------+ \n",
      "             *             \n",
      "             *             \n",
      "             *             \n",
      "  +--------------------+   \n",
      "  | ChatPromptTemplate |   \n",
      "  +--------------------+   \n",
      "             *             \n",
      "             *             \n",
      "             *             \n",
      "      +------------+       \n",
      "      | ChatOpenAI |       \n",
      "      +------------+       \n",
      "             *             \n",
      "             *             \n",
      "             *             \n",
      "    +-----------------+    \n",
      "    | StrOutputParser |    \n",
      "    +-----------------+    \n",
      "             *             \n",
      "             *             \n",
      "             *             \n",
      "  +--------------------+   \n",
      "  | ChatPromptTemplate |   \n",
      "  +--------------------+   \n",
      "             *             \n",
      "             *             \n",
      "             *             \n",
      "      +------------+       \n",
      "      | ChatOpenAI |       \n",
      "      +------------+       \n",
      "             *             \n",
      "             *             \n",
      "             *             \n",
      "    +-----------------+    \n",
      "    | StrOutputParser |    \n",
      "    +-----------------+    \n",
      "             *             \n",
      "             *             \n",
      "             *             \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Medical Diagnosis Chain"
   ],
   "metadata": {
    "id": "anGt-9AC0LNt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Example invocation to test the chain\n",
    "result = main_chain.invoke({\"symptoms\": \"fever, cough, and shortness of breath\"})\n",
    "print(\"Recommended Lab Exams:\", result)"
   ],
   "metadata": {
    "id": "rs0FhDLvguZr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545644752,
     "user_tz": -240,
     "elapsed": 1915,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9cc1da7e-222e-41b4-a419-4765d6418ac2"
   },
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recommended Lab Exams: To confirm a diagnosis of pneumonia, influenza, or COVID-19, the following lab tests may be recommended:\n",
      "\n",
      "1. Chest X-ray or CT scan: This imaging test can show signs of pneumonia in the lungs.\n",
      "\n",
      "2. Blood tests: A complete blood count (CBC) and a blood culture test can help identify an infection and indicate the severity of the illness.\n",
      "\n",
      "3. Sputum culture: This test can identify the specific bacteria causing pneumonia and determine the most effective antibiotic treatment.\n",
      "\n",
      "4. Influenza test: A nasal or throat swab test can detect the presence of the influenza virus.\n",
      "\n",
      "5. COVID-19 test: A nasal or throat swab test (PCR test) can confirm if the person has COVID-19.\n",
      "\n",
      "It is important to consult a healthcare provider for proper evaluation and testing to determine the exact cause of the symptoms and receive appropriate treatment.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "**Expected Result**: The system should first identify potential diseases (like COVID-19, pneumonia) and then recommend appropriate lab tests (PCR, chest X-ray, blood tests).\n"
   ],
   "metadata": {
    "id": "kjped0_70R2o"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Complex Parallel Chain for Scientific Research\n",
    "\n",
    "### Scientific Hypothesis Testing Chain\n",
    "This chain demonstrates how to create complex workflows that branch and merge information.\n"
   ],
   "metadata": {
    "id": "igs9FjvU0S1G"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# Prompt for generating a hypothesis based on an observation\n",
    "prompt_observation = ChatPromptTemplate.from_template(\n",
    "    \"Based on the observation: {observation}, what is a possible biological explanation or hypothesis?\"\n",
    ")\n",
    "\n",
    "# Prompt for suggesting an experiment to test a hypothesis\n",
    "prompt_hypothesis = ChatPromptTemplate.from_template(\n",
    "    \"What experiment could we perform to test the hypothesis: {hypothesis}, considering the condition: {condition}?\"\n",
    ")\n",
    "\n",
    "# Prompt for predicting the outcome of an experiment\n",
    "prompt_experiment = ChatPromptTemplate.from_template(\n",
    "    \"Given the setup: {experiment_setup}, what might be the expected outcome of this experiment?\"\n",
    ")"
   ],
   "metadata": {
    "id": "TLGIjFslkXJi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545644756,
     "user_tz": -240,
     "elapsed": 2,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    }
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build Multi-Step Research Chain"
   ],
   "metadata": {
    "id": "vajvT1Kk0efW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Chain to generate a hypothesis from an observation\n",
    "hypothesis_generator = (\n",
    "    {\"observation\": RunnablePassthrough()}\n",
    "    | prompt_observation\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Chain to suggest an experiment based on the hypothesis, merging with additional input\n",
    "experiment_suggestion = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"hypothesis\": hypothesis_generator,\n",
    "            \"condition\": RunnablePassthrough(),\n",
    "        }  # Merging the hypothesis output with a new input 'condition'\n",
    "    )\n",
    "    | prompt_hypothesis\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Chain to predict the outcome of the suggested experiment\n",
    "experiment_outcome = (\n",
    "    {\"experiment_setup\": experiment_suggestion}\n",
    "    | prompt_experiment\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "metadata": {
    "id": "jMJJMrAa0fSI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545644791,
     "user_tz": -240,
     "elapsed": 12,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    }
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize Research Chain"
   ],
   "metadata": {
    "id": "HYiuWc4D0k-4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "experiment_outcome.get_graph().print_ascii()"
   ],
   "metadata": {
    "id": "ie9Obe8AabpV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545644836,
     "user_tz": -240,
     "elapsed": 43,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5521b03b-7920-4c0e-bee5-55fd2bd64c11"
   },
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "           +---------------------------------+         \n",
      "           | Parallel<experiment_setup>Input |         \n",
      "           +---------------------------------+         \n",
      "                            *                          \n",
      "                            *                          \n",
      "                            *                          \n",
      "         +-------------------------------------+       \n",
      "         | Parallel<hypothesis,condition>Input |       \n",
      "         +-------------------------------------+       \n",
      "                   **               ***                \n",
      "                ***                    ***             \n",
      "              **                          ***          \n",
      "    +-------------+                          **        \n",
      "    | Passthrough |                           *        \n",
      "    +-------------+                           *        \n",
      "           *                                  *        \n",
      "           *                                  *        \n",
      "           *                                  *        \n",
      "+--------------------+                        *        \n",
      "| ChatPromptTemplate |                        *        \n",
      "+--------------------+                        *        \n",
      "           *                                  *        \n",
      "           *                                  *        \n",
      "           *                                  *        \n",
      "    +------------+                            *        \n",
      "    | ChatOpenAI |                            *        \n",
      "    +------------+                            *        \n",
      "           *                                  *        \n",
      "           *                                  *        \n",
      "           *                                  *        \n",
      "  +-----------------+                 +-------------+  \n",
      "  | StrOutputParser |                 | Passthrough |  \n",
      "  +-----------------+                 +-------------+  \n",
      "                   **               ***                \n",
      "                     ***         ***                   \n",
      "                        **     **                      \n",
      "        +--------------------------------------+       \n",
      "        | Parallel<hypothesis,condition>Output |       \n",
      "        +--------------------------------------+       \n",
      "                            *                          \n",
      "                            *                          \n",
      "                            *                          \n",
      "                 +--------------------+                \n",
      "                 | ChatPromptTemplate |                \n",
      "                 +--------------------+                \n",
      "                            *                          \n",
      "                            *                          \n",
      "                            *                          \n",
      "                     +------------+                    \n",
      "                     | ChatOpenAI |                    \n",
      "                     +------------+                    \n",
      "                            *                          \n",
      "                            *                          \n",
      "                            *                          \n",
      "                   +-----------------+                 \n",
      "                   | StrOutputParser |                 \n",
      "                   +-----------------+                 \n",
      "                            *                          \n",
      "                            *                          \n",
      "                            *                          \n",
      "                 +--------------------+                \n",
      "                 | ChatPromptTemplate |                \n",
      "                 +--------------------+                \n",
      "                            *                          \n",
      "                            *                          \n",
      "                            *                          \n",
      "                     +------------+                    \n",
      "                     | ChatOpenAI |                    \n",
      "                     +------------+                    \n",
      "                            *                          \n",
      "                            *                          \n",
      "                            *                          \n",
      "                   +-----------------+                 \n",
      "                   | StrOutputParser |                 \n",
      "                   +-----------------+                 \n",
      "                            *                          \n",
      "                            *                          \n",
      "                            *                          \n",
      "                +-----------------------+              \n",
      "                | StrOutputParserOutput |              \n",
      "                +-----------------------+              \n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Scientific Research Chain"
   ],
   "metadata": {
    "id": "nmiZDm090nTC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Example invocation to test the chain\n",
    "result = experiment_outcome.invoke(\n",
    "    {\n",
    "        \"observation\": \"Pea plants with round seeds produce mostly round seed offspring, even when crossed with wrinkled seeds.\",\n",
    "        \"condition\": \"controlled pollination\",\n",
    "    }\n",
    ")\n",
    "print(\"Experiment Prediction:\", result)"
   ],
   "metadata": {
    "id": "4ayewyLwkZX3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545649152,
     "user_tz": -240,
     "elapsed": 4318,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3251ee3b-6190-49b3-d189-5ce0b3ea4ab6"
   },
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Experiment Prediction: The expected outcome of this experiment, if the hypothesis is true, would be that the majority of the offspring plants produced from the controlled cross between pea plants with round seeds and pea plants with wrinkled seeds would have round seeds. This is because in this scenario, round seeds would be the dominant trait and wrinkled seeds would be the recessive trait. \n",
      "\n",
      "Therefore, if the hypothesis is correct, the offspring plants would exhibit a phenotypic ratio of approximately 3:1, with three-quarters of the offspring plants having round seeds and one-quarter having wrinkled seeds. This outcome would provide evidence to support the hypothesis that the trait for seed shape is controlled by a single gene with dominant and recessive alleles.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Expected Result**: The system should generate a hypothesis about dominant/recessive traits, suggest controlled breeding experiments, and predict outcomes based on genetic principles.\n"
   ],
   "metadata": {
    "id": "99hbeNTL0qrH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Debate Chain with Argument Analysis\n",
    "\n",
    "### Creating a Balanced Debate System\n",
    "This chain demonstrates how to create a system that can analyze arguments from multiple perspectives."
   ],
   "metadata": {
    "id": "GJMRFPFe0q-v"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# Prompt to generate an initial argument about a controversial life science topic\n",
    "generate_argument = (\n",
    "    ChatPromptTemplate.from_template(\"Generate an argument about: {input}\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    "    | {\"base_argument\": RunnablePassthrough()}\n",
    ")\n",
    "\n",
    "# Chain to list the positive aspects (pros) of the argument\n",
    "arguments_for = (\n",
    "    ChatPromptTemplate.from_template(\n",
    "        \"List the pros or positive aspects of: {base_argument}\"\n",
    "    )\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Chain to list the negative aspects (cons) of the argument\n",
    "arguments_against = (\n",
    "    ChatPromptTemplate.from_template(\n",
    "        \"List the cons or negative aspects of: {base_argument}\"\n",
    "    )\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Template for the final responder to synthesize the debate\n",
    "final_responder = (\n",
    "    ChatPromptTemplate.from_template(\n",
    "        \"Discussion on {input}:\\n\\nPros:\\n{arguments_for}\\n\\nCons:\\n{arguments_against}\\n\\nCan you provide a balanced conclusion?\"\n",
    "    )\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "metadata": {
    "id": "xl6wPwJascZW",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545649153,
     "user_tz": -240,
     "elapsed": 29,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    }
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Complete Debate Chain"
   ],
   "metadata": {
    "id": "ZB3yggQb0yU7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Full chain to manage the debate\n",
    "main_chain = (\n",
    "    generate_argument\n",
    "    | {\n",
    "        \"arguments_for\": arguments_for,\n",
    "        \"arguments_against\": arguments_against,\n",
    "        \"input\": itemgetter(\"base_argument\"),\n",
    "    }\n",
    "    | final_responder\n",
    ")"
   ],
   "metadata": {
    "id": "oIwz45ni00zv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545649154,
     "user_tz": -240,
     "elapsed": 28,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    }
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize Debate Chain"
   ],
   "metadata": {
    "id": "XyjPSPsq01-i"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "main_chain.get_graph().print_ascii()"
   ],
   "metadata": {
    "id": "mUudb75laZFj",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545649156,
     "user_tz": -240,
     "elapsed": 28,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d88f102b-7e19-4509-afe6-3419819205a2"
   },
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                   +-------------+                               \n",
      "                                   | PromptInput |                               \n",
      "                                   +-------------+                               \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                               +--------------------+                            \n",
      "                               | ChatPromptTemplate |                            \n",
      "                               +--------------------+                            \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                   +------------+                                \n",
      "                                   | ChatOpenAI |                                \n",
      "                                   +------------+                                \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                 +-----------------+                             \n",
      "                                 | StrOutputParser |                             \n",
      "                                 +-----------------+                             \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                   +-------------+                               \n",
      "                                   | Passthrough |                               \n",
      "                                   +-------------+                               \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "              +------------------------------------------------------+           \n",
      "              | Parallel<arguments_for,arguments_against,input>Input |           \n",
      "              +------------------------------------------------------+           \n",
      "                        ******            *             *****                    \n",
      "                   *****                   *                 *****               \n",
      "                ***                        *                      ******         \n",
      "+--------------------+          +--------------------+                  ***      \n",
      "| ChatPromptTemplate |          | ChatPromptTemplate |                    *      \n",
      "+--------------------+          +--------------------+                    *      \n",
      "           *                               *                              *      \n",
      "           *                               *                              *      \n",
      "           *                               *                              *      \n",
      "    +------------+                  +------------+                        *      \n",
      "    | ChatOpenAI |                  | ChatOpenAI |                        *      \n",
      "    +------------+                  +------------+                        *      \n",
      "           *                               *                              *      \n",
      "           *                               *                              *      \n",
      "           *                               *                              *      \n",
      "  +-----------------+             +-----------------+               +--------+   \n",
      "  | StrOutputParser |             | StrOutputParser |             **| Lambda |   \n",
      "  +-----------------+***          +-----------------+        *****  +--------+   \n",
      "                        ******             *           ******                    \n",
      "                              *****       *       *****                          \n",
      "                                   ***    *    ***                               \n",
      "              +-------------------------------------------------------+          \n",
      "              | Parallel<arguments_for,arguments_against,input>Output |          \n",
      "              +-------------------------------------------------------+          \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                               +--------------------+                            \n",
      "                               | ChatPromptTemplate |                            \n",
      "                               +--------------------+                            \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                   +------------+                                \n",
      "                                   | ChatOpenAI |                                \n",
      "                                   +------------+                                \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                 +-----------------+                             \n",
      "                                 | StrOutputParser |                             \n",
      "                                 +-----------------+                             \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                              +-----------------------+                          \n",
      "                              | StrOutputParserOutput |                          \n",
      "                              +-----------------------+                          \n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Debate Chain"
   ],
   "metadata": {
    "id": "0VssmCYd05SI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "result = main_chain.invoke({\"input\": \"the use of CRISPR technology in human embryos\"})\n",
    "print(\"Debate Summary:\", result)"
   ],
   "metadata": {
    "id": "k1w0EVYkseK-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545655338,
     "user_tz": -240,
     "elapsed": 6182,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2bbb56d8-605a-4bfd-a1c0-e48ed9b4aa81"
   },
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Debate Summary: In conclusion, the use of CRISPR technology in human embryos has the potential to bring significant benefits in terms of eliminating genetic diseases and disorders, improving quality of life, and advancing medical treatments. However, it is crucial to address the ethical concerns raised by critics, including the potential for designer babies, widening social and economic inequalities, unintended consequences, and the need for responsible and ethical use of this technology.\n",
      "\n",
      "It is important to carefully consider the implications of using CRISPR technology in embryos and to establish ethical guidelines and regulations to ensure that it is used responsibly and for the greater good of society. Further research and discussion are needed to weigh the potential benefits and risks of this technology and to determine the best way forward in harnessing its potential while mitigating any negative consequences.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Expected Result**: The system should generate a balanced analysis covering benefits (treating genetic diseases) and concerns (ethical implications, safety) of CRISPR technology."
   ],
   "metadata": {
    "id": "z6hd7VLO0_bF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## Part 7: Custom Chain Functions\n",
    "\n",
    "### What are Custom Chain Functions?\n",
    "Custom chain functions allow you to create reusable chain components with the `@chain` decorator, providing more flexibility than standard LCEL chains.\n",
    "\n"
   ],
   "metadata": {
    "id": "QvCg4Knh0_0f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Drug Discovery Analysis Chain"
   ],
   "metadata": {
    "id": "8UQ8HM_z1C9o"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "generate_scenario_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Generate a hypothetical drug discovery scenario involving {topic}\"\n",
    ")\n",
    "analyze_scenario_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What are the key challenges and potential solutions in this scenario: {scenario}\"\n",
    ")\n",
    "\n",
    "\n",
    "@chain\n",
    "def drug_discovery_analysis(topic):\n",
    "    # Generate a scenario based on the given drug discovery topic\n",
    "    initial_scenario = generate_scenario_prompt.invoke({\"topic\": topic})\n",
    "    scenario_description = ChatOpenAI().invoke(initial_scenario)\n",
    "    parsed_scenario = StrOutputParser().invoke(scenario_description)\n",
    "\n",
    "    # Analyze the generated scenario to identify challenges and potential solutions\n",
    "    analysis_chain = analyze_scenario_prompt | ChatOpenAI() | StrOutputParser()\n",
    "    scenario_analysis = analysis_chain.invoke({\"scenario\": parsed_scenario})\n",
    "\n",
    "    return scenario_analysis"
   ],
   "metadata": {
    "id": "4jIfclu6hwIU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545655370,
     "user_tz": -240,
     "elapsed": 31,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    }
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "topic_focus = \"Alzheimer's disease\"\n",
    "scenario_analysis_result = drug_discovery_analysis.invoke(topic_focus)\n",
    "print(\"Analysis of Drug Discovery Scenario:\", scenario_analysis_result)"
   ],
   "metadata": {
    "id": "4FHa23jnaYgt",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752545662541,
     "user_tz": -240,
     "elapsed": 7168,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "cc1953ae-3fc7-4f10-b1a8-603977497b8d"
   },
   "execution_count": 41,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Analysis of Drug Discovery Scenario: Key challenges in this scenario:\n",
      "\n",
      "1. Safety and efficacy: The primary challenge is ensuring the safety and efficacy of the drug candidate in clinical trials. Adverse effects or lack of therapeutic benefit could pose significant hurdles to regulatory approval.\n",
      "\n",
      "2. Scaling up production: Once the drug candidate shows promising results in clinical trials, scaling up production to meet the demand for a widespread patient population can be a challenge. Ensuring consistent quality and supply of the drug is crucial.\n",
      "\n",
      "3. Regulatory hurdles: Navigating the regulatory approval process can be complex and time-consuming. Meeting the requirements of regulatory agencies to demonstrate the safety and efficacy of the drug candidate is essential for market approval.\n",
      "\n",
      "4. Cost of development: Developing a new drug can be expensive, and securing funding for ongoing research and clinical trials can be a challenge. Finding financial resources to support the development process is a key hurdle.\n",
      "\n",
      "Potential solutions:\n",
      "\n",
      "1. Collaboration and partnerships: Collaborating with other research institutions, biopharmaceutical companies, and regulatory agencies can help overcome challenges in drug development. Sharing resources and expertise can accelerate the process and improve the chances of success.\n",
      "\n",
      "2. Early engagement with regulators: Engaging with regulatory agencies early in the drug development process can help anticipate and address potential hurdles. This proactive approach can facilitate a smoother regulatory approval process.\n",
      "\n",
      "3. Innovative funding strategies: Exploring alternative funding sources, such as government grants, partnerships with philanthropic organizations, or venture capital funding, can help secure financial resources for drug development.\n",
      "\n",
      "4. Patient involvement: Involving patients and advocacy groups in the drug development process can provide valuable insights and ensure that the drug candidate meets the needs of the patient population. Patient input can help guide research priorities and shape clinical trial design.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "**Expected Result**: The system should generate a realistic drug discovery scenario for Alzheimer's disease and analyze key challenges like blood-brain barrier penetration, clinical trial design, and regulatory approval.\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated several key concepts in building personal assistants with LangChain:\n",
    "\n",
    "1. **History-Aware Retrieval**: Building systems that understand conversation context\n",
    "2. **LCEL Chains**: Using the pipe operator for clean, declarative chain building\n",
    "3. **Parallel Processing**: Improving efficiency with simultaneous operations\n",
    "4. **Sequential Chains**: Multi-step reasoning for complex tasks\n",
    "5. **Complex Workflows**: Branching and merging information streams\n",
    "6. **Custom Chain Functions**: Creating reusable chain components\n",
    "\n",
    "These patterns form the foundation for building sophisticated AI assistants that can handle complex, multi-step reasoning tasks while maintaining context and providing accurate, relevant responses."
   ],
   "metadata": {
    "id": "t1aqEi4i1IRV"
   }
  }
 ]
}
